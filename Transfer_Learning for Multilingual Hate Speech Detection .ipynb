{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset,DataLoader,RandomSampler,SequentialSampler,TensorDataset,WeightedRandomSampler\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import os,math\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_linear_schedule_with_warmup\n",
    "import pickle\n",
    "from sklearn import dummy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLMRobertaTokenizer,\\\n",
    "    XLMRobertaForSequenceClassification,XLMRobertaConfig,XLMRobertaModel\n",
    "from transformers import AutoModelForMaskedLM,AutoConfig,AutoTokenizer,\\\n",
    "        AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import logging\n",
    "logging.basicConfig(filename='example10.log',level=logging.INFO)\n",
    "Le = LabelEncoder()\n",
    "dm = dummy.DummyClassifier(strategy=\"stratified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHES = 5\n",
    "BATCH_SZ = 32\n",
    "MAX_LENGTH = 128\n",
    "LEARNING_RATE = 3e-5   #for finetuning on German Tweets\n",
    "#LEARNING_RATE = 2e-5\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert Pretrained Language Model, should be finetunned on English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config = AutoConfig.from_pretrained(\"../results/config.json\")\n",
    "#tokenizer = XLMRobertaTokenizer.from_pretrained(\"../results/\")\n",
    "#trg_model = AutoModelForSequenceClassification.from_pretrained(\"../results/\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#config = AutoConfig.from_pretrained(\"Spanish_LangModel/config.json\")\n",
    "#tokenizer = XLMRobertaTokenizer.from_pretrained(\"Spanish_LangModel/\")\n",
    "#trg_model = AutoModelForSequenceClassification.from_pretrained(\"Spanish_LangModel/\")\n",
    "\n",
    "\n",
    "\n",
    "#config = AutoConfig.from_pretrained(\"../Italian_LangModel/config.json\")\n",
    "#tokenizer = XLMRobertaTokenizer.from_pretrained(\"../Italian_LangModel/\")\n",
    "#trg_model = AutoModelForSequenceClassification.from_pretrained(\"../Italian_LangModel/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def createLangDataset(lang):\n",
    "    for f in os.listdir(\".\"):\n",
    "        if os.path.isdir(f) and not f.startswith(\".\") and not f.endswith(\"_LangModel\"):\n",
    "            print(f)\n",
    "            files = os.listdir(f)\n",
    "            eng = [name for name in files if name.startswith(lang)]\n",
    "            print(eng)\n",
    "            data_frames = [pd.read_csv(os.path.join(f,f1)) for f1 in eng]\n",
    "            eng_all = pd.concat(data_frames)\n",
    "            eng_all.drop(\"Unnamed: 0\", axis=1,inplace=True)\n",
    "            eng_all.to_csv(lang+\"_\"+f+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createLangDataset(\"English\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"English_train.csv\")\n",
    "#text = [df.iloc[0][\"text\"],df.iloc[1][\"text\"]]\n",
    "#label = torch.tensor([df.iloc[0][\"label\"],df.iloc[1][\"label\"]],dtype=torch.long)\n",
    "#inputs = tokenizer(text,return_attention_mask=True,\n",
    "#                   return_token_type_ids=True,return_tensors=\"pt\",padding=\"max_length\",\n",
    "#                  max_length=MAX_LENGTH,truncation=True)\n",
    "#loss , logits = model(**inputs,labels=label)\n",
    "#print(classification_report(label,torch.argmax(logits,dim=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataset(tokenizer,df):\n",
    "    text = df[\"text\"].tolist()\n",
    "    Le.fit(df[\"label\"])\n",
    "    #label = torch.tensor(Le.transform(df[\"label\"]),dtype=torch.float) # CHANGE POINT FOR BCELogitLoss\n",
    "    label = torch.tensor(Le.transform(df[\"label\"]),dtype=torch.long)\n",
    "    inputs = tokenizer(text,return_attention_mask=True,\n",
    "                   return_token_type_ids=True,return_tensors=\"pt\",padding=\"max_length\",\n",
    "                  max_length=MAX_LENGTH,truncation=True)\n",
    "    dataset = TensorDataset(inputs[\"input_ids\"],inputs[\"attention_mask\"],\n",
    "                           inputs[\"token_type_ids\"],label)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDataLoaders(lang):\n",
    "    \n",
    "    df_train = pd.read_csv(lang+\"_train.csv\")\n",
    "    labels = torch.tensor(df_train[\"label\"].tolist(),dtype=torch.long)\n",
    "    print(torch.unique(labels,return_counts=True))\n",
    "    class_count = torch.tensor([ (t == labels).sum() for t in torch.unique(labels,sorted=True)])\n",
    "    #weight = 1.0/class_count.float()\n",
    "    #weight = 1-class_count/torch.sum(class_count)\n",
    "    weight = torch.sum(class_count) / class_count\n",
    "    print(weight)\n",
    "    sample_wts = torch.tensor([weight[t] for t in labels])\n",
    "    dm.fit(df_train[\"text\"],df_train[\"label\"])\n",
    "    sampler = WeightedRandomSampler(sample_wts,len(sample_wts),replacement=True) \n",
    "    df = pd.read_csv(lang+\"_train.csv\")\n",
    "    #df_f = df[[\"text\"]]\n",
    "    #df_f.to_csv(lang+\"__\"+\"Train.txt\",header=None,index=False)\n",
    "    train_dataset = createDataset(tokenizer,df_train)\n",
    "    train_loader= DataLoader(train_dataset,batch_size=BATCH_SZ,sampler=sampler,shuffle=False)\n",
    "    #train_loader= DataLoader(train_dataset,batch_size=BATCH_SZ,shuffle=False)\n",
    "\n",
    "    df_eval = pd.read_csv(lang+\"_val.csv\")\n",
    "    #df_f = df_eval[[\"text\"]]\n",
    "    #df_f.to_csv(lang+\"__\"+\"Eval.txt\",header=None,index=False)\n",
    "    eval_dataset = createDataset(tokenizer,df_eval)\n",
    "    eval_loader= DataLoader(eval_dataset,batch_size=BATCH_SZ,shuffle=False)\n",
    "\n",
    "    df_test = pd.read_csv(lang+\"_test.csv\")\n",
    "    test_dataset = createDataset(tokenizer,df_test)\n",
    "    test_loader= DataLoader(test_dataset,batch_size=BATCH_SZ,shuffle=False)\n",
    "    probs = dm.predict_proba(df_test[\"text\"])\n",
    "    print(\"Random Classifier Result: \",\n",
    "          roc_auc_score(df_test[\"label\"],probs[:,1]))\n",
    "    \n",
    "    return (train_loader,eval_loader,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader,eval_loader,test_loader = prepareDataLoaders(\"Italian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_loader)),print(len(eval_loader)),print(len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three model variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HateClassifier(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HateClassifier,self).__init__()\n",
    "        self.base_model_prefix = \"roberta\"\n",
    "        self.config = XLMRobertaConfig.from_pretrained(\"xlm-roberta-base\",base_model_prefix=self.base_model_prefix)\n",
    "        self.model = XLMRobertaForSequenceClassification.from_pretrained(\"xlm-roberta-base\",\n",
    "                                                                         config=self.config)\n",
    "    \n",
    "    def forward(self,inputs,labels):\n",
    "        outputs = self.model(**inputs,labels=labels)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HClassifier(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HClassifier,self).__init__()\n",
    "        self.model = XLMRobertaModel.from_pretrained(\"xlm-roberta-base\")\n",
    "        self.drop = torch.nn.Dropout(0.5)\n",
    "        self.fc = torch.nn.Linear(768,1)\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        _, outputs = self.model(**inputs)\n",
    "        outputs = self.drop(outputs)\n",
    "        outputs = self.fc(outputs)\n",
    "        outputs = self.tanh(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XLMRobertaModel.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model in full data, random 128, 256 examples by setting flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_loader,eval_loader,run_type=[False,False]):\n",
    "    train_loss_counter = []\n",
    "    best_loss = math.inf\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay= ['bias','LayerNorm.bias','LayerNorm.weight']\n",
    "    optimizer_parameters = [\n",
    "    {'params': [p for n,p in param_optimizer if not any (nd in n for nd in no_decay)],\n",
    "    'weight_decay':0.01},\n",
    "    {'params':[p for n,p in param_optimizer if any(nd in n for nd in no_decay)], \n",
    "    'weight_decay':0.0}]\n",
    "    num_train_steps = len(train_loader)*EPOCHES\n",
    "    optimizer = AdamW(optimizer_parameters,lr=LEARNING_RATE)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                               num_warmup_steps=2,\n",
    "                                               num_training_steps=num_train_steps)   \n",
    "    #optimizer = torch.optim.Adam(params=model.parameters(),lr=LEARNING_RATE)\n",
    "    for epoch in range(EPOCHES):\n",
    "        model.train()\n",
    "        epoch_loss_counter = []\n",
    "        for ids,batch in tqdm(enumerate(train_loader),total=len(train_loader)):\n",
    "            if run_type[0] and ids > 4:\n",
    "                break\n",
    "            if run_type[1] and ids > 7:\n",
    "                break\n",
    "            optimizer.zero_grad()\n",
    "            inputs = {\"input_ids\":batch[0].cuda(),\n",
    "                     \"attention_mask\":batch[1].cuda(),\n",
    "                     \"token_type_ids\":batch[2].cuda()}\n",
    "            labels = batch[3].cuda()\n",
    "            #print(torch.unique(batch[3].cpu(),return_counts=True))\n",
    "            output = model(**inputs,labels=labels)\n",
    "            loss, logits = output.loss , output.logits\n",
    "            #outputs = model(inputs)\n",
    "            #loss = criterion(outputs.squeeze(1),labels)\n",
    "            loss = loss.mean()\n",
    "            epoch_loss_counter.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        \n",
    "        train_loss_counter.append(np.mean(epoch_loss_counter))\n",
    "        model.eval()\n",
    "        actual = []\n",
    "        predicted = []\n",
    "        with torch.no_grad():\n",
    "            eval_loss_counter = []\n",
    "            for ids,batch in tqdm(enumerate(eval_loader),total=len(eval_loader)):\n",
    "                inputs = {\"input_ids\":batch[0].cuda(),\n",
    "                          \"attention_mask\":batch[1].cuda(),\n",
    "                          \"token_type_ids\":batch[2].cuda()}\n",
    "                labels = batch[3].cuda()\n",
    "                output = model(**inputs,labels=labels)\n",
    "                loss, logits = output.loss , output.logits\n",
    "                loss = loss.mean()\n",
    "                #outputs = model(inputs)\n",
    "                #loss = criterion(outputs.squeeze(1),labels)\n",
    "                #predicted.append(torch.round(torch.sigmoid(outputs.squeeze(1).cpu())))\n",
    "                predicted.append(torch.argmax(logits,dim=1).cpu())\n",
    "                actual.append(labels.cpu())\n",
    "                eval_loss_counter.append(loss.item())\n",
    "            if best_loss > np.mean(eval_loss_counter):\n",
    "                best_loss = np.mean(eval_loss_counter)\n",
    "                model_to_save = model.module if hasattr(model, 'module') else model\n",
    "                torch.save(model_to_save.state_dict(),\"torch_model_pretrained_italian_finet_eng_adapted_italian.bin\")\n",
    "                #torch.save({\n",
    "                #    'model_state_dict':model.state_dict(),\n",
    "                #    'optimizer_state_dict':optimizer.state_dict(),\n",
    "                #    'loss':best_loss,},'saved_model.pth')\n",
    "            print(epoch,np.mean(epoch_loss_counter),np.mean(eval_loss_counter))\n",
    "            print(classification_report(torch.cat(actual),torch.cat(predicted)))\n",
    "            logging.info(\"Validation Report\")\n",
    "            logging.info('%d %f %f',epoch,np.mean(epoch_loss_counter),np.mean(eval_loss_counter))\n",
    "            logging.info(classification_report(torch.cat(actual),torch.cat(predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test trained model , save test predictions and probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,test_loader):\n",
    "        model.eval()\n",
    "        actual = []\n",
    "        predicted = []\n",
    "        predicted_score = []\n",
    "        criterion = torch.nn.BCEWithLogitsLoss()\n",
    "        with torch.no_grad():\n",
    "            for ids,batch in tqdm(enumerate(test_loader),total=len(test_loader)):\n",
    "                inputs = {\"input_ids\":batch[0].cuda(),\n",
    "                          \"attention_mask\":batch[1].cuda(),\n",
    "                          \"token_type_ids\":batch[2].cuda()}\n",
    "                labels = batch[3].cuda()\n",
    "                #outputs = model(inputs)\n",
    "                #loss = criterion(outputs.squeeze(1),labels)\n",
    "                #loss = loss.mean()\n",
    "                #predicted.append(torch.round(torch.sigmoid(outputs.squeeze(1).cpu())))\n",
    "                output = model(**inputs,labels=labels)\n",
    "                loss, logits = output.loss , output.logits\n",
    "                p_score = F.softmax(logits,dim=1)\n",
    "                #print(torch.max(logits,dim=1))\n",
    "                loss = loss.mean()\n",
    "                #print(torch.argmax(logits,dim=1).cpu())\n",
    "                #print(p_score)\n",
    "                #print(labels.cpu())\n",
    "                predicted.append(torch.argmax(logits,dim=1).cpu())\n",
    "                predicted_score.append(p_score[:,1].cpu())\n",
    "                actual.append(labels.cpu())\n",
    "            print(classification_report(torch.cat(actual),torch.cat(predicted)))\n",
    "            print(roc_auc_score(torch.cat(actual),torch.cat(predicted_score)))\n",
    "            logging.info(\"Test Report\")\n",
    "            logging.info(classification_report(torch.cat(actual),torch.cat(predicted)))\n",
    "            logging.info(roc_auc_score(torch.cat(actual),torch.cat(predicted_score)))\n",
    "            pickle.dump(actual,open(\"Actual_13.p\",\"wb\"))\n",
    "            pickle.dump(predicted_score,open(\"Predicted_scores_13.p\",\"wb\"))\n",
    "            pickle.dump(predicted,open(\"Predicted_13.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How outputs of different languages are saved\n",
    "# Spanish from Actual_6,7,8,9 \n",
    "# Italian from Actual_10,11,12,13 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy example of model outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = HClassifier()\n",
    "# inputs = tokenizer([\"Hello, my dog is cute\",\"Pluto is Mad\"], return_tensors=\"pt\",return_token_type_ids=True,\n",
    "#                   padding=\"max_length\",max_length=10,truncation=True)\n",
    "# inputs = {\"input_ids\":inputs[\"input_ids\"],\"attention_mask\":inputs[\"attention_mask\"],\"token_type_ids\":inputs[\"token_type_ids\"]}\n",
    "# outputs = models(inputs)\n",
    "# print(outputs.squeeze(1).shape)\n",
    "# print(torch.round(torch.sigmoid(outputs.squeeze(1).cpu())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = HateClassifier()\n",
    "# inputs = tokenizer([\"Hello, my dog is cute\",\"Pluto is Mad\"], return_tensors=\"pt\",return_token_type_ids=True,\n",
    "#                    padding=\"max_length\",max_length=10,truncation=True)\n",
    "# inputs = {\"input_ids\":inputs[\"input_ids\"],\"attention_mask\":inputs[\"attention_mask\"],\"token_type_ids\":inputs[\"token_type_ids\"]}\n",
    "# labels = torch.tensor(torch.ones(2),dtype=torch.long)\n",
    "# outputs  = models(inputs,labels)\n",
    "# print(outputs.logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on full or partial data\n",
    "### load adapted model\n",
    "### apply adapted model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model,train_loader,eval_loader,test_loader):\n",
    "    train(model.cuda(),train_loader,eval_loader,[False,True])\n",
    "    #model_state_dict = torch.load(\"torch_model_finet_eng_adapted_italian.bin\")\n",
    "    #model_state_dict = torch.load(\"torch_model_pretrained_spanish_finet_eng_adapted_spanish.bin\")\n",
    "    model_state_dict = torch.load(\"torch_model_pretrained_italian_finet_eng_adapted_italian.bin\")\n",
    "    #model_state_dict = torch.load(\"torch_model_finet_eng_adapted_spanish.bin\")\n",
    "    #model_state_dict = torch.load(\"torch_model_finet_eng_adapted_german.bin\")\n",
    "    #model_state_dict = torch.load(\"torch_model_pretrain_germ_finet_eng_adapted_germ.bin\")\n",
    "    #model_state_dict = torch.load(\"torch_model_pretrained_germ_finet_eng_adapted.bin\")\n",
    "    config = XLMRobertaConfig.from_pretrained(\"xlm-roberta-base\",base_model_prefix=\"roberta\")\n",
    "    model = XLMRobertaForSequenceClassification.from_pretrained(\"xlm-roberta-base\",config=config)\n",
    "    #model = HateClassifier()\n",
    "    #checkpoint = torch.load(\"saved_model.pth\")\n",
    "    #model_best = HateClassifier(checkpoint[\"model_state_dict\"])\n",
    "    model.load_state_dict(model_state_dict)\n",
    "    test(model.cuda(),test_loader)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training from Scratch\n",
    "\n",
    "config = XLMRobertaConfig.from_pretrained(\"xlm-roberta-base\",base_model_prefix=\"roberta\")\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(\"xlm-roberta-base\",config=config)\n",
    "\n",
    "#model = HateClassifier()\n",
    "\n",
    "#model_state_dict = torch.load(\"torch_model1_transfer.bin\") # Pretrained on German Tweets\n",
    "\n",
    "#model_state_dict = torch.load(\"torch_model1.bin\") # filetuned on English XLMSequenceClassification\n",
    "\n",
    "#model_state_dict = torch.load(\"torch_model.bin\")   # filetuned on English HateClassifier\n",
    "model_state_dict = torch.load(\"torch_model_pretrained_italian_finet_eng.bin\")\n",
    "#model_state_dict = torch.load(\"torch_model_pretrained_germ_finet_eng.bin\")\n",
    "#model_state_dict = torch.load(\"torch_model_pretrained_spanish_finet_eng.bin\")\n",
    "#model_state_dict = torch.load(\"torch_model_pretrained_ita\")\n",
    "\n",
    "model.load_state_dict(model_state_dict)\n",
    "\n",
    "# For finetuning TRG-MLM\n",
    "\n",
    "#model = trg_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incase of multiple GPU's for better utilisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run train / test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = main(model,train_loader,eval_loader,test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrospective analysis of the predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = pickle.load(open(\"Actual_10.p\",\"rb\"))\n",
    "predicted_score = pickle.load(open(\"Predicted_scores_10.p\",\"rb\"))\n",
    "predicted = pickle.load(open(\"Predicted_10.p\",\"rb\"))\n",
    "\n",
    "actual = torch.cat(actual)\n",
    "predicted = torch.cat(predicted)\n",
    "predicted_score = torch.cat(predicted_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.87      0.77      1195\n",
      "           1       0.60      0.32      0.42       717\n",
      "\n",
      "    accuracy                           0.67      1912\n",
      "   macro avg       0.64      0.60      0.59      1912\n",
      "weighted avg       0.65      0.67      0.64      1912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(actual,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6087089978583474\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(actual,predicted_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_score[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual2 = pickle.load(open(\"Actual_11.p\",\"rb\"))\n",
    "predicted_score2 = pickle.load(open(\"Predicted_scores_11.p\",\"rb\"))\n",
    "predicted2 = pickle.load(open(\"Predicted_11.p\",\"rb\"))\n",
    "\n",
    "actual2 = torch.cat(actual2)\n",
    "predicted2 = torch.cat(predicted2)\n",
    "predicted_score2 = torch.cat(predicted_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.77      0.80      1195\n",
      "           1       0.66      0.73      0.69       717\n",
      "\n",
      "    accuracy                           0.76      1912\n",
      "   macro avg       0.74      0.75      0.75      1912\n",
      "weighted avg       0.77      0.76      0.76      1912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(actual2,predicted2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual2[55:65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted2[55:65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual3 = pickle.load(open(\"Actual_12.p\",\"rb\"))\n",
    "predicted_score3 = pickle.load(open(\"Predicted_scores_12.p\",\"rb\"))\n",
    "predicted3 = pickle.load(open(\"Predicted_12.p\",\"rb\"))\n",
    "\n",
    "actual3 = torch.cat(actual3)\n",
    "predicted3 = torch.cat(predicted3)\n",
    "predicted_score3 = torch.cat(predicted_score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.88      0.78      1195\n",
      "           1       0.66      0.38      0.48       717\n",
      "\n",
      "    accuracy                           0.69      1912\n",
      "   macro avg       0.68      0.63      0.63      1912\n",
      "weighted avg       0.69      0.69      0.67      1912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(actual3,predicted3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual3[0:24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted3[55:65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted[0:24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual4 = pickle.load(open(\"Actual_13.p\",\"rb\"))\n",
    "predicted_score4 = pickle.load(open(\"Predicted_scores_13.p\",\"rb\"))\n",
    "predicted4 = pickle.load(open(\"Predicted_13.p\",\"rb\"))\n",
    "\n",
    "actual4 = torch.cat(actual4)\n",
    "predicted4 = torch.cat(predicted4)\n",
    "predicted_score4 = torch.cat(predicted_score4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.77      0.81      1195\n",
      "           1       0.67      0.81      0.74       717\n",
      "\n",
      "    accuracy                           0.78      1912\n",
      "   macro avg       0.77      0.79      0.77      1912\n",
      "weighted avg       0.80      0.78      0.78      1912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(actual4,predicted4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 350\n",
    "b = 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual[a:b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted[a:b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted2[a:b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted3[a:b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted4[a:b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.77      0.81      1195\n",
      "           1       0.67      0.81      0.74       717\n",
      "\n",
      "    accuracy                           0.78      1912\n",
      "   macro avg       0.77      0.79      0.77      1912\n",
      "weighted avg       0.80      0.78      0.78      1912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(actual,predicted4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(actual,predicted3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roc_auc_score(actual,predicted_score2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Italian_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ambasciatore : Teheran spera che l'Occidente c...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#ultimenotizie #news #notizie: Le rom messe in...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I padroni della guerra non dormono mai  #Trump...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@FabianaDeNisi @matteosalvinimi Ma perchè esse...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>..e i laici contro islamici e cristiani,ovviam...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@ClaudioDeglinn2 Cessava l'invasione di migran...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#Migranti e terroristi islamici quantè facile ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Andiamo al Cairo, in una scuola di suore franc...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>#dallavostraparte Ha fatto bene il ristoratore...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>#papamilano2017 abbraccia gli #islamici, un ab...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Ambasciatore : Teheran spera che l'Occidente c...    0.0\n",
       "1  #ultimenotizie #news #notizie: Le rom messe in...    0.0\n",
       "2  I padroni della guerra non dormono mai  #Trump...    0.0\n",
       "3  @FabianaDeNisi @matteosalvinimi Ma perchè esse...    0.0\n",
       "4  ..e i laici contro islamici e cristiani,ovviam...    0.0\n",
       "5  @ClaudioDeglinn2 Cessava l'invasione di migran...    0.0\n",
       "6  #Migranti e terroristi islamici quantè facile ...    1.0\n",
       "7  Andiamo al Cairo, in una scuola di suore franc...    0.0\n",
       "8  #dallavostraparte Ha fatto bene il ristoratore...    1.0\n",
       "9  #papamilano2017 abbraccia gli #islamici, un ab...    1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = 354"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quel figlio di Vanna marchi....se la pigliasse ne ano più profondo'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[ids][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[ids][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
